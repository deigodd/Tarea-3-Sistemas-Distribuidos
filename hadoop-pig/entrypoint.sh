#!/bin/bash

# ConfiguraciÃ³n de las env
HADOOP_HOME=/opt/hadoop
PIG_HOME=/opt/pig
DATA_DIR=/data
HDFS_INPUT=/input
HDFS_OUTPUT=/output
PIG_SCRIPT=/scripts/process_waze_alerts.pig
PIG_SCRIPT2=/scripts/processing.pig
CSV_FILE=datos_clean.csv
HDFS_FILE=waze_data.csv

# Iniciar servicios SSH y Hadoop
echo "âš™ï¸ Iniciando servicios..."
echo "Iniciando SSH..."
sudo service ssh start

# (no tiene mucho sentido este paso porque por ahora no se guarda en volumen persistente)
echo "Verificando si es necesario formatear NameNode "
if [ ! -d "$HADOOP_HOME/data/namenode/current" ]; then
    $HADOOP_HOME/bin/hdfs namenode -format -force
fi

ssh-keyscan -H localhost >> ~/.ssh/known_hosts 2>/dev/null
ssh-keyscan -H 0.0.0.0 >> ~/.ssh/known_hosts 2>/dev/null

# iniciar servicios de Hadoop - importante -> ver logs en caso de falla
echo "Iniciando HDFS (start-dfs.sh)..."
$HADOOP_HOME/sbin/start-dfs.sh

echo "Iniciando YARN (start-yarn.sh)..."
$HADOOP_HOME/sbin/start-yarn.sh

echo "â³ Esperando inicializaciÃ³n de HDFS..."
sleep 10

# Configurar estructura HDFS - bÃ¡sicamente se crean los directorios de entrada y salida para los datos
echo "ðŸ“š Configurando estructura HDFS..."
$HADOOP_HOME/bin/hdfs dfs -mkdir -p $HDFS_INPUT
$HADOOP_HOME/bin/hdfs dfs -mkdir -p $HDFS_OUTPUT
$HADOOP_HOME/bin/hdfs dfs -chmod -R 755 $HDFS_INPUT
$HADOOP_HOME/bin/hdfs dfs -chmod -R 755 $HDFS_OUTPUT

# Esperar y verificar archivo CSV
echo "ðŸ” Esperando archivo CSV..."
while [ ! -f "$DATA_DIR/$CSV_FILE" ]; do
    echo "â³ Esperando que $CSV_FILE estÃ© disponible..."
    sleep 15
done

# Subir archivo a HDFS con reintentos
MAX_RETRIES=3
RETRY_COUNT=0
UPLOAD_SUCCESS=false

while [ $RETRY_COUNT -lt $MAX_RETRIES ] && [ "$UPLOAD_SUCCESS" = false ]; do
    echo "â¬†ï¸ Subiendo archivo a HDFS (Intento $((RETRY_COUNT+1))/$MAX_RETRIES)..."

    $HADOOP_HOME/bin/hdfs dfs -put -f $DATA_DIR/$CSV_FILE $HDFS_INPUT/$HDFS_FILE

    if [ $? -eq 0 ]; then
        HDFS_SIZE=$($HADOOP_HOME/bin/hdfs dfs -du -s $HDFS_INPUT/$HDFS_FILE | awk '{print $1}')
        LOCAL_SIZE=$(du -b $DATA_DIR/$CSV_FILE | awk '{print $1}')

        if [ "$HDFS_SIZE" -eq "$LOCAL_SIZE" ]; then
            echo "âœ“ Archivo subido correctamente ($HDFS_SIZE bytes)"
            UPLOAD_SUCCESS=true
        else
            echo "âœ— Los tamaÃ±os no coinciden (HDFS: $HDFS_SIZE vs Local: $LOCAL_SIZE)"
        fi
    else
        echo "âœ— FallÃ³ el intento $((RETRY_COUNT+1))"
    fi

    RETRY_COUNT=$((RETRY_COUNT+1))
    sleep 5
done

if [ "$UPLOAD_SUCCESS" = false ]; then
    echo "âœ— Error: No se pudo subir el archivo despuÃ©s de $MAX_RETRIES intentos"
    exit 1
fi

# Configurar entorno Pig y rutas para este
export PIG_CLASSPATH=$HADOOP_HOME/etc/hadoop:$HADOOP_HOME/share/hadoop/common/*:$HADOOP_HOME/share/hadoop/mapreduce/*:$HADOOP_HOME/share/hadoop/hdfs/*:$HADOOP_HOME/share/hadoop/yarn/*

# Esperar que YARN estÃ© listo
echo "â³ Esperando que YARN estÃ© listo..."
until $HADOOP_HOME/bin/yarn node -list 2>/dev/null | grep -q "RUNNING"; do
    sleep 5
done

echo "ðŸ“„ Listado del archivo en HDFS:"
$HADOOP_HOME/bin/hdfs dfs -ls $HDFS_INPUT/$HDFS_FILE

echo "Iniciando JobHistory Server..."
$HADOOP_HOME/sbin/mr-jobhistory-daemon.sh start historyserver

# Ejecutar script Pig - este es el procesamiento de los datos
echo "ðŸ· Ejecutando script Pig para la filtraciÃ³n y homogeneizaciÃ³n de los datos"
$PIG_HOME/bin/pig -f $PIG_SCRIPT


echo "Subiendo cleaned_records al HDFS..."

$HADOOP_HOME/bin/hdfs dfs -rm -r /input/cleaned_records

$HADOOP_HOME/bin/hdfs dfs -put /output/cleaned_records /input/

$HADOOP_HOME/bin/hdfs dfs -ls /input/cleaned_records

# Ejecutar segundo script Pig - acÃ¡ es el anÃ¡lisis de los datos
echo "ðŸ· Ejecutando el segundo script Pig para el procesamiento de los datos"
sleep 5
$PIG_HOME/bin/pig -f $PIG_SCRIPT2

# acÃ¡ se hace cat de los outputs de Pig
echo "Se inicia el cat de los outputs de Pig"

echo "Resultados del primer script Pig (filtrado y homogeneizaciÃ³n):"
cat /output/cleaned_records/part-r-00000
sleep 5

echo "Resultados del segundo script Pig (anÃ¡lisis de datos):"
echo "Primero el analisis por comuna"
cat /output/analysis_by_city/part-r-00000
sleep 5

echo "Ahora el analisis por hora (los dias estan en epoch)"
cat /output/analysis_by_day/part-r-00000
sleep 5

echo "Ahora el analisis por calle y comuna"
cat /output/analysis_by_street_city/part-r-00000
sleep 5

echo "Ahora el analisis por tipo de alerta"
cat /output/analysis_by_type/part-r-00000
sleep 5

echo "Ahora el analisis por tipo de alerta y comuna"
cat /output/analysis_by_type_city/part-r-00000
sleep 5

# Mantener contenedor activo - esto para poder ver el output mas que nada
# echo "âœ“ Procesamiento completado. Contenedor activo..."
# tail -f /dev/null ----> esto para mantener el contenedor activo

# Finalizar el contenedor
echo "âœ“ Procesamiento completado. Contenedor finalizado."